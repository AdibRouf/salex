<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Saliency Based Natural Language Explanations for Autonomous Vehicles</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            border-radius: 20px;
            margin-top: 20px;
            margin-bottom: 20px;
        }

        header {
            text-align: center;
            padding: 40px 0;
            background: linear-gradient(45deg, #2c3e50, #3498db);
            border-radius: 15px;
            margin-bottom: 40px;
            position: relative;
            overflow: hidden;
        }

        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 20"><defs><radialGradient id="a" cx="50%" cy="40%" r="50%"><stop offset="0%" stop-color="rgba(255,255,255,.1)"/><stop offset="100%" stop-color="rgba(255,255,255,0)"/></radialGradient></defs><rect width="100" height="20" fill="url(%23a)"/></svg>') repeat-x;
            animation: shimmer 3s ease-in-out infinite;
        }

        @keyframes shimmer {
            0%, 100% { opacity: 0; }
            50% { opacity: 1; }
        }

        h1 {
            color: white;
            font-size: 2.8em;
            font-weight: 700;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
            position: relative;
            z-index: 1;
        }

        .authors {
            color: #ecf0f1;
            font-size: 1.3em;
            font-weight: 300;
            position: relative;
            z-index: 1;
        }

        .section {
            margin: 50px 0;
            padding: 30px;
            background: rgba(255, 255, 255, 0.8);
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .section:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
        }

        .section-title {
            font-size: 2.2em;
            color: #2c3e50;
            margin-bottom: 25px;
            text-align: center;
            position: relative;
            padding-bottom: 15px;
        }

        .section-title::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 80px;
            height: 4px;
            background: linear-gradient(45deg, #3498db, #9b59b6);
            border-radius: 2px;
        }

        .overview-text {
            font-size: 1.1em;
            color: #555;
            text-align: center;
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.8;
        }

        .video-section {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            align-items: start;
            margin: 40px 0;
        }

        .video-single {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 40px 0;
        }

        .video-container {
            width: 100%;
            max-width: 500px;
            background: #000;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.2);
            position: relative;
            transition: transform 0.3s ease;
        }

        .video-container:hover {
            transform: scale(1.02);
        }

        .video-placeholder {
            width: 100%;
            height: 280px;
            background: linear-gradient(45deg, #34495e, #2c3e50);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 1.1em;
            position: relative;
        }

        .video-placeholder::before {
            content: '▶';
            font-size: 3em;
            margin-bottom: 10px;
            opacity: 0.7;
        }

        .explanation-box {
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            padding: 25px;
            border-radius: 12px;
            border-left: 5px solid #3498db;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);
        }

        .explanation-text {
            font-size: 1.05em;
            color: #2c3e50;
            line-height: 1.7;
        }

        .dual-video-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 30px 0;
        }

        .video-label {
            text-align: center;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 1.1em;
        }

        .caption-box {
            background: linear-gradient(135deg, #f1f3f4, #e8eaed);
            padding: 20px;
            border-radius: 10px;
            margin-top: 15px;
            border-left: 4px solid #4285f4;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
        }

        .caption-text {
            font-size: 1.05em;
            color: #1f2937;
            line-height: 1.6;
            font-style: italic;
        }

        .example-container {
            margin: 40px 0;
            padding: 25px;
            background: rgba(255, 255, 255, 0.6);
            border-radius: 12px;
            border: 2px solid rgba(52, 152, 219, 0.2);
        }

        .example-title {
            font-size: 1.4em;
            color: #2c3e50;
            margin-bottom: 20px;
            text-align: center;
            font-weight: 600;
        }

        @media (max-width: 768px) {
            .container {
                margin: 10px;
                padding: 15px;
            }

            h1 {
                font-size: 2.2em;
            }

            .authors {
                font-size: 1.1em;
            }

            .video-section {
                grid-template-columns: 1fr;
                gap: 20px;
            }

            .dual-video-container {
                grid-template-columns: 1fr;
            }

            .section-title {
                font-size: 1.8em;
            }
        }

        .pulse {
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Saliency Based Natural Language Explanations for Autonomous Vehicles</h1>
            <div class="authors">Daniel Baker • Adib Rouf • Guo Zhefan</div>
        </header>

        <section class="section">
            <h2 class="section-title">Overview</h2>
            <div class="overview-text">
                <p>Modern end-to-end autonomous vehicle (AV) systems achieve impressive performance but remain opaque "black-boxes," raising concerns about trust and safety. Explainable AI (XAI) methods such as saliency maps highlight the input regions that influence decisions, offering a window into the model's internal reasoning. However, these visualizations can be difficult for many users to interpret, making natural language explanations a more accessible alternative. Existing approaches often generate captions of driving videos that sound reasonable but are generated without considering the model's internal computation and decision process. To address this, we propose a multimodal large language model (M-LLM) framework that integrates saliency maps into caption generation, ensuring explanations are explicitly tied to the regions the AV focused on when taking an action. This grounds explanations in the model's real decision-making. Our method achieves this by modifying the vision encoder to distinguish salient regions from context and by emphasizing those regions during captioning. In doing so, we provide more faithful, region-specific explanations of AV behavior, offering new insights into multimodal models and improving interpretability in safety-critical AI.</p>
            </div>
        </section>

        <section class="section">
            <h2 class="section-title">Video Analysis</h2>
            <div class="explanation-box" style="margin-bottom: 30px;">
                <div class="explanation-text">
                    This video demonstrates our model <strong>without</strong> the incorporation of a saliency map. We can see that it effectively provides a justification of the action of the ego vehicle. Although this description reflects what a human driver may do, we cannot say for certain that the vehicle shares our reasoning.
                </div>
            </div>
            
            <div class="video-single">
                <div class="video-container">
                    <video class="video-placeholder" width="100%" height="280" controls>
                        <source src="videos/input_video.mp4" type="video/mp4">
                        <div class="video-placeholder pulse">
                            Video could not be loaded<br>
                            <small>videos/input_video.mp4</small>
                        </div>
                    </video>
                </div>
                <div class="caption-box">
                    <div class="caption-text">
                        <em>Predicted Caption:</em> "The car is slowing down because the car in front of it is slowing down. "
                    </div>
                </div>
            </div>
        </section>

        <section class="section">
            <h2 class="section-title">Heatmap Analysis</h2>
            <div class="explanation-box" style="margin-bottom: 30px;">
                <div class="explanation-text">
                    These examples demonstrate how incorporating saliency maps results in more faithful descriptions. For both of these examples, we first generate captions without saliency maps to serve as a baseline. We see the captions are plausible. However, when introducing a hypothetical saliency map representing the focus of an AV, we see that the model may have truly had different reasoning. Consider the first video where the truck pulls ahead and the pedestrian crosses the street. A heat map reveals that the AV was not waiting for the light to change but actually stopped because of the pedestrian. We leverage this valuable information and provide a caption that reflects this reasoning. In the second example we have a similar case where the raw caption may cite that the model is primarily driving due to the road being clear, when in reality it is driving through many intersections because the light is also green.
                </div>
            </div>

            <div class="example-container">
                <h3 class="example-title">Example 1: Pedestrian Detection</h3>
                <div class="video-single">
                    <div class="video-container">
                        <video class="video-placeholder" width="100%" height="280" controls>
                            <source src="/shared/healthinfolab/xai4av/pedestrian_overlay.mp4" type="video/mp4">
                            <div class="video-placeholder pulse">
                                Video could not be loaded<br>
                                <small>/shared/healthinfolab/xai4av/pedestrian_overlay.mp4</small>
                            </div>
                        </video>
                    </div>
                    <div class="caption-box">
                        <div class="caption-text">
                            <em>Predicted Caption:</em> [Caption will appear here when video is processed]
                        </div>
                    </div>
                </div>
            </div>

            <div class="example-container">
                <h3 class="example-title">Example 2: Traffic Light Navigation</h3>
                <div class="video-single">
                    <div class="video-container">
                        <video class="video-placeholder" width="100%" height="280" controls>
                            <source src="/shared/healthinfolab/xai4av/traffic_lights_overlay.mp4" type="video/mp4">
                            <div class="video-placeholder pulse">
                                Video could not be loaded<br>
                                <small>/shared/healthinfolab/xai4av/traffic_lights_overlay.mp4</small>
                            </div>
                        </video>
                    </div>
                    <div class="caption-box">
                        <div class="caption-text">
                            <em>Predicted Caption:</em> [Caption will appear here when video is processed]
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="section">
            <h2 class="section-title">Model Demonstration</h2>
            <div class="explanation-box" style="margin-bottom: 30px;">
                <div class="explanation-text">
                    This comprehensive demo showcases our GUI interface, demonstrating both the baseline captioning and saliency-enhanced captioning capabilities across different driving scenarios.
                </div>
            </div>
            
            <div class="video-single">
                <div class="video-container">
                    <video class="video-placeholder" width="100%" height="400" controls>
                        <source src="videos/gui_demo.mp4" type="video/mp4">
                        <div class="video-placeholder pulse">
                            Video could not be loaded<br>
                            <small>videos/gui_demo.mp4</small>
                        </div>
                    </video>
                </div>
            </div>
        </section>
    </div>
</body>
</html>